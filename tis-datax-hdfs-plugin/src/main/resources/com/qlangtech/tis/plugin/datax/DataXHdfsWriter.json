{
  "defaultFS": {
    "help": "描述：Hadoop hdfs文件系统namenode节点地址。格式：hdfs://ip:端口；例如：hdfs://127.0.0.1:9000"
  },
  "fileType": {
    "help": "描述：文件的类型，目前只支持用户配置为"text"或"orc"。 "
  },
  "path": {
    "help": "描述：存储到Hadoop hdfs文件系统的路径信息，HdfsWriter会根据并发配置在Path目录下写入多个文件。为与hive表关联，请填写hive表在hdfs上的存储路径。例：Hive上设置的数据仓库的存储路径为：/user/hive/warehouse/ ，已建立数据库：test，表：hello；则对应的存储路径为：/user/hive/warehouse/test.db/hello  "
  },
  "fileName": {
    "help": "描述：HdfsWriter写入时的文件名，实际执行时会在该文件名后添加随机的后缀作为每个线程写入实际文件名。 "
  },
  "column": {
    "help": "描述：写入数据的字段，不支持对部分列写入。为与hive中表关联，需要指定表中所有字段名和字段类型，其中：name指定字段名，type指定字段类型。 "
  },
  "writeMode": {
    "help": "描述：hdfswriter写入前数据清理处理模式： "
  },
  "fieldDelimiter": {
    "help": "描述：hdfswriter写入时的字段分隔符,"
  },
  "compress": {
    "help": "描述：hdfs文件压缩类型，默认不填写意味着没有压缩。其中：text类型文件支持压缩类型有gzip、bzip2;orc类型文件支持的压缩类型有NONE、SNAPPY（需要用户安装SnappyCodec）。 "
  },
  "hadoopConfig": {
    "help": "描述：hadoopConfig里可以配置与Hadoop相关的一些高级参数，比如HA的配置。"
  },
  "encoding": {
    "help": "描述：写文件的编码配置。"
  },
  "haveKerberos": {
    "help": "描述：是否有Kerberos认证，默认false"
  },
  "kerberosKeytabFilePath": {
    "help": "描述：Kerberos认证 keytab文件路径，绝对路径"
  },
  "kerberosPrincipal": {
    "help": "描述：Kerberos认证Principal名，如xxxx/hadoopclient@xxx.xxx "
  },
  "template": {
    "label": "配置模版",
    "dftVal": "com.qlangtech.tis.plugin.datax.DataXHdfsWriter.getDftTemplate()",
    "rows": 18
  }
}